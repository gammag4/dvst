{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b9a4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = torch.from_numpy(np.load('./res/tmp/plenoptic/coffee_martini/poses_bounds.npy'))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e766840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 3, 4]),\n",
       " (torch.Size([18]), torch.Size([18])),\n",
       " (torch.Size([18]), torch.Size([18])),\n",
       " torch.Size([18]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_poses_raw(data):\n",
    "    mat, close, far = data[:, :-2].reshape((-1, 3, 5)), data[:, -2], data[:, -1]\n",
    "    T, mat2 = mat[:, :, :-1], mat[:, :, -1:]\n",
    "    h, w, f = mat2[:, 0, 0], mat2[:, 1, 0], mat2[:, 2, 0]\n",
    "\n",
    "    return T, (h, w), (close, far), f\n",
    "\n",
    "T, (h, w), (c, f), F = get_poses_raw(data)\n",
    "\n",
    "T.shape, (h.shape, w.shape), (c.shape, f.shape), F.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15b0623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.1732e-02,  9.9435e-01, -1.0391e-01,  4.4396e-01,  2.0280e+03,\n",
       "          9.9975e-01,  2.1133e-02, -6.8671e-03, -1.1035e+00,  2.7040e+03,\n",
       "         -4.6324e-03, -1.0403e-01, -9.9456e-01, -3.4993e-01,  1.4608e+03,\n",
       "          8.8314e+00,  1.0978e+02], dtype=torch.float64),\n",
       " tensor([[-0.0217,  0.9943, -0.1039,  0.4440],\n",
       "         [ 0.9998,  0.0211, -0.0069, -1.1035],\n",
       "         [-0.0046, -0.1040, -0.9946, -0.3499]], dtype=torch.float64),\n",
       " (tensor(2028., dtype=torch.float64), tensor(2704., dtype=torch.float64)),\n",
       " (tensor(8.8314, dtype=torch.float64), tensor(109.7754, dtype=torch.float64)),\n",
       " tensor(1460.7543, dtype=torch.float64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, :], T[0, :, :], (h[0], w[0]), (c[0], f[0]), F[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5351b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 3, 3]),\n",
       " torch.Size([18, 3, 4]),\n",
       " (torch.Size([18]), torch.Size([18])))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def colmap_poses_to_intrinsics_extrinsics(data):\n",
    "    mat, close, far = data[:, :-2].reshape((-1, 3, 5)), data[:, -2], data[:, -1]\n",
    "    T, mat2 = mat[:, :, :-1], mat[:, :, -1:]\n",
    "    h, w, f = mat2[:, 0, 0], mat2[:, 1, 0], mat2[:, 2, 0]\n",
    "\n",
    "    # Since we only have width, height and focal point, the intrinsics matrix will give imprecise results\n",
    "    K = torch.zeros((T.shape[0], 3, 3))\n",
    "    K[:, 0, 0], K[:, 1, 1], K[:, 2, 2], K[:, 0, 2], K[:, 1, 2] = f, f, 1, w / 2, h / 2\n",
    "\n",
    "    return K, T, (h, w)\n",
    "\n",
    "K, T, (h, w) = colmap_poses_to_intrinsics_extrinsics(data)\n",
    "\n",
    "K.shape, T.shape, (h.shape, w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7abb0984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.4608e+03, 0.0000e+00, 1.3520e+03],\n",
       "         [0.0000e+00, 1.4608e+03, 1.0140e+03],\n",
       "         [0.0000e+00, 0.0000e+00, 1.0000e+00]]),\n",
       " tensor([[-0.0217,  0.9943, -0.1039,  0.4440],\n",
       "         [ 0.9998,  0.0211, -0.0069, -1.1035],\n",
       "         [-0.0046, -0.1040, -0.9946, -0.3499]], dtype=torch.float64),\n",
       " (tensor(2028., dtype=torch.float64), tensor(2704., dtype=torch.float64)))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[0, :, :], T[0, :, :], (h[0], w[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32479664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(basedir, factor=None, width=None, height=None):\n",
    "    # Taken from repos/LLFF/llff/poses/pose_utils.py\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    img0 = [os.path.join(basedir, 'images', f) for f in sorted(os.listdir(os.path.join(basedir, 'images'))) \\\n",
    "            if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')][0]\n",
    "    sh = imageio.imread(img0).shape\n",
    "    \n",
    "    sfx = ''\n",
    "    \n",
    "    # just resizes the images and sends to a new folder with suffix images_{}x{} or images_{}\n",
    "    if factor is not None:\n",
    "        sfx = '_{}'.format(factor)\n",
    "        minify(basedir, factors=[factor])\n",
    "        factor = factor\n",
    "    elif height is not None:\n",
    "        factor = sh[0] / float(height)\n",
    "        width = int(sh[1] / factor)\n",
    "        minify(basedir, resolutions=[[height, width]])\n",
    "        sfx = '_{}x{}'.format(width, height)\n",
    "    elif width is not None:\n",
    "        factor = sh[1] / float(width)\n",
    "        height = int(sh[0] / factor)\n",
    "        minify(basedir, resolutions=[[height, width]])\n",
    "        sfx = '_{}x{}'.format(width, height)\n",
    "    else:\n",
    "        factor = 1\n",
    "    \n",
    "    imgdir = os.path.join(basedir, 'images' + sfx)\n",
    "    if not os.path.exists(imgdir):\n",
    "        print( imgdir, 'does not exist, returning' )\n",
    "        return\n",
    "    \n",
    "    imgfiles = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir)) if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')]\n",
    "    if poses.shape[-1] != len(imgfiles):\n",
    "        print( 'Mismatch between imgs {} and poses {} !!!!'.format(len(imgfiles), poses.shape[-1]) )\n",
    "        return\n",
    "    \n",
    "    # new data after resizing is width/factor, height/factor, focal/factor (factor 2 halves the image, 4 gets 1/4th of the size, and so on)\n",
    "     sh = imageio.imread(imgfiles[0]).shape\n",
    "    poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
    "    poses[2, 4, :] = poses[2, 4, :] * 1./factor\n",
    "    \n",
    "    return poses, bds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
