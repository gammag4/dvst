{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from enum import Enum\n",
    "import hashlib\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, RandomSampler, SubsetRandomSampler, BatchSampler\n",
    "import torchvision\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.utils import save_image\n",
    "from torchinfo import summary\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as callbacks\n",
    "from xformers.factory.model_factory import xFormer, xFormerConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatePluckerRayEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Only images with even width and height\n",
    "        # vecs contains the right (vecs[b, 0, :]), up (vecs[b, 1, :]), and forward (vecs[b, 2, :]) unit vectors of the camera in the camera frame\n",
    "        # Shapes: (B,), (B,), (B, 3, 3), (B, 3, 4), (B, C, H, W)\n",
    "        f, wx, vecs, T, img = batch\n",
    "        R, t = T[:, :, :3], T[:, :, 3] # Shapes: (B, 3, 3), (B, 3)\n",
    "        \n",
    "        ry, rx = img.shape[-2:]\n",
    "        wy = wx * (ry / rx) # Shape (B,)\n",
    "\n",
    "        # Creating tensors with indices\n",
    "        i = torch.arange(rx, dtype=torch.float64, device=img.device)\n",
    "        j = torch.arange(ry, dtype=torch.float64, device=img.device)\n",
    "        \n",
    "        # Computing displacements\n",
    "        dx = ((i + 0.5) / rx - 0.5) # Shape: (W,)\n",
    "        dy = -((j + 0.5) / ry - 0.5) # Shape: (H,)\n",
    "\n",
    "        dx2 = torch.einsum('b,i->bi', wx, dx) # dx2_bi = wx_b * dx_i\n",
    "        dy2 = torch.einsum('b,j->bj', wy, dy) # dy2_bj = wy_b * dy_j\n",
    "        \n",
    "        # Computing pixel point in camera frame\n",
    "        v1 = torch.einsum('bi,bc->bic', dx2, vecs[:, 0, :]) # v1_bic = dx2_bi * vr_c\n",
    "        v2 = torch.einsum('bj,bc->bjc', dy2, vecs[:, 1, :]) # v2_bjc = dy2_bj * vu_c\n",
    "        v3 = torch.einsum('b,bc->bc', f, vecs[:, 2, :]) # v3_bc = f_b * vf_c\n",
    "\n",
    "        # q_bijc = v1_bic + v2_bjc + v3_bc\n",
    "        q = v1[:, :, None, :] + v2[:, None, :, :] + v3[:, None, None, :] # TODO test speed with unsqueeze\n",
    "        \n",
    "        p = t[:, :, None, None]\n",
    "        l = torch.einsum('bijc,bkc->bkji', q, R) # l_bijk = q_bijc * R_bkc # TODO test speed with unsqueeze\n",
    "        m = torch.cross(p, l, dim=1)\n",
    "        \n",
    "        pl = torch.cat([img, l, m], dim=1)\n",
    "        return pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0., -0., -0., -0.],\n",
       "          [-0., -0., -0., -0.],\n",
       "          [ 0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.]],\n",
       "\n",
       "         [[ 3.,  3.,  3.,  3.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [-1., -1., -1., -1.],\n",
       "          [-3., -3., -3., -3.]]],\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0., -0.],\n",
       "          [-0., -0., -0., -0.],\n",
       "          [ 0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.]],\n",
       "\n",
       "         [[ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.]],\n",
       "\n",
       "         [[ 3.,  3.,  3.,  3.],\n",
       "          [ 1.,  1.,  1.,  1.],\n",
       "          [-1., -1., -1., -1.],\n",
       "          [-3., -3., -3., -3.]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = CreatePluckerRayEmbedding()\n",
    "\n",
    "device = 'cuda'\n",
    "B = 2\n",
    "f = torch.tensor(1, device=device).repeat(B)\n",
    "wx = torch.tensor(8, device=device).repeat(B)\n",
    "vecs = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, -1]], dtype=torch.float64, device=device).repeat(B, 1, 1)\n",
    "T = torch.tensor([[1, 0, 0, 1], [0, 1, 0, 0], [0, 0, 1, 0]], dtype=torch.float64, device=device).repeat(B, 1, 1)\n",
    "img = torch.zeros((B, 3, 4, 4), dtype=torch.float64, device=device)\n",
    "emb((f, wx, vecs, T, img))[:, 6:, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
