{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from enum import Enum\n",
    "import hashlib\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import random\n",
    "import progressbar\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d\n",
    "from open3d.visualization import draw_plotly\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import einops\n",
    "import einx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.amp as amp\n",
    "import torch.nn.utils as utils\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, RandomSampler, SubsetRandomSampler, BatchSampler\n",
    "import torchvision\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.utils import save_image\n",
    "from torchinfo import summary\n",
    "from torchcodec.decoders import VideoDecoder\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.raw_panoptic_dataset import RawPanopticDataset\n",
    "from src.datasets.raw_plenoptic_dataset import RawPlenopticDataset\n",
    "from src.datasets.full_dataset import FullDataset\n",
    "\n",
    "from src.model.pose_encoder import compute_pad, compute_octaves, compute_view_rays\n",
    "\n",
    "from src.config import load_config\n",
    "\n",
    "from src.model import PoseEncoder, DVST, latent_aggregators\n",
    "\n",
    "from src.draw import get_camera_geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0+cu126'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DVST Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.bfloat16, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make it easier to pass around and validate configs\n",
    "config = load_config('res/config.yaml')\n",
    "\n",
    "config.setup.ddp.rank, config.setup.amp.dtype, config.setup.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_full = FullDataset(config.train.data.datasets).to(device)\n",
    "len(dataset_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DVST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DVST(config=config.model).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 7.87M; Trainable params: 7.87M\n"
     ]
    }
   ],
   "source": [
    "from src.utils import print_num_params\n",
    "\n",
    "print_num_params(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sources': [{'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc10f8fbc80>,\n",
       "   'K': tensor([[1.6547e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.5388e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.0433e-04,  0.0000e+00, -5.8016e-01],\n",
       "           [ 0.0000e+00,  6.4986e-04, -3.5093e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.5296, -0.0115,  0.8482],\n",
       "            [ 0.6366,  0.6554,  0.4064],\n",
       "            [-0.5606,  0.7552, -0.3397]]], device='cuda:0'),\n",
       "   't': tensor([[ -5.6521,  81.6465, 378.2934]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e69e1df0>,\n",
       "   'K': tensor([[1.4357e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3433e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.9655e-04,  0.0000e+00, -6.6869e-01],\n",
       "           [ 0.0000e+00,  7.4443e-04, -4.0199e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.9317, -0.0109, -0.3631],\n",
       "            [-0.0217,  0.9994,  0.0257],\n",
       "            [ 0.3626,  0.0318, -0.9314]]], device='cuda:0'),\n",
       "   't': tensor([[ -8.1925, 143.5502, 280.5694]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])}],\n",
       " 'queries': [{'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e68b7bf0>,\n",
       "   'K': tensor([[1.4302e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3539e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.9920e-04,  0.0000e+00, -6.7124e-01],\n",
       "           [ 0.0000e+00,  7.3858e-04, -3.9883e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.9970,  0.0545, -0.0555],\n",
       "            [-0.0107,  0.6108,  0.7917],\n",
       "            [ 0.0771,  0.7899, -0.6084]]], device='cuda:0'),\n",
       "   't': tensor([[-17.6922,  64.0220, 380.7844]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e678e870>,\n",
       "   'K': tensor([[1.4107e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3299e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 7.0888e-04,  0.0000e+00, -6.8053e-01],\n",
       "           [ 0.0000e+00,  7.5194e-04, -4.0605e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.6212, -0.0284,  0.7832],\n",
       "            [ 0.0751,  0.9926,  0.0955],\n",
       "            [-0.7801,  0.1182, -0.6144]]], device='cuda:0'),\n",
       "   't': tensor([[-15.3971, 117.3840, 288.2436]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2cc62f080>,\n",
       "   'K': tensor([[1.4097e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3722e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 7.0936e-04,  0.0000e+00, -6.8099e-01],\n",
       "           [ 0.0000e+00,  7.2874e-04, -3.9352e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[ 0.9448, -0.0489, -0.3241],\n",
       "            [-0.2141,  0.6567, -0.7231],\n",
       "            [ 0.2482,  0.7526,  0.6100]]], device='cuda:0'),\n",
       "   't': tensor([[ -8.3128,  83.8591, 377.3930]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc10f576d50>,\n",
       "   'K': tensor([[1.4083e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3423e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 7.1006e-04,  0.0000e+00, -6.8166e-01],\n",
       "           [ 0.0000e+00,  7.4501e-04, -4.0230e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[ 0.0536,  0.0240,  0.9983],\n",
       "            [ 0.6374,  0.7687, -0.0527],\n",
       "            [-0.7687,  0.6391,  0.0259]]], device='cuda:0'),\n",
       "   't': tensor([[  6.6445, 105.7245, 361.4694]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2d43a1a00>,\n",
       "   'K': tensor([[1.6629e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.5779e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.0134e-04,  0.0000e+00, -5.7729e-01],\n",
       "           [ 0.0000e+00,  6.3377e-04, -3.4223e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[ 0.1356,  0.0332, -0.9902],\n",
       "            [-0.0915,  0.9956,  0.0208],\n",
       "            [ 0.9865,  0.0878,  0.1381]]], device='cuda:0'),\n",
       "   't': tensor([[ 20.3223, 126.5647, 284.8756]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2cc726150>,\n",
       "   'K': tensor([[1.4118e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3716e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 7.0833e-04,  0.0000e+00, -6.8000e-01],\n",
       "           [ 0.0000e+00,  7.2906e-04, -3.9369e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.9415, -0.0377,  0.3348],\n",
       "            [ 0.1807,  0.7824,  0.5960],\n",
       "            [-0.2844,  0.6217, -0.7298]]], device='cuda:0'),\n",
       "   't': tensor([[ -7.3450, 113.0683, 359.1882]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc10f8fbc80>,\n",
       "   'K': tensor([[1.6547e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.5388e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.0433e-04,  0.0000e+00, -5.8016e-01],\n",
       "           [ 0.0000e+00,  6.4986e-04, -3.5093e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.5296, -0.0115,  0.8482],\n",
       "            [ 0.6366,  0.6554,  0.4064],\n",
       "            [-0.5606,  0.7552, -0.3397]]], device='cuda:0'),\n",
       "   't': tensor([[ -5.6521,  81.6465, 378.2934]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])},\n",
       "  {'video': <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e69e1df0>,\n",
       "   'K': tensor([[1.4357e+03, 0.0000e+00, 9.6000e+02],\n",
       "           [0.0000e+00, 1.3433e+03, 5.4000e+02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00]], device='cuda:0'),\n",
       "   'Kinv': tensor([[ 6.9655e-04,  0.0000e+00, -6.6869e-01],\n",
       "           [ 0.0000e+00,  7.4443e-04, -4.0199e-01],\n",
       "           [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0'),\n",
       "   'R': tensor([[[-0.9317, -0.0109, -0.3631],\n",
       "            [-0.0217,  0.9994,  0.0257],\n",
       "            [ 0.3626,  0.0318, -0.9314]]], device='cuda:0'),\n",
       "   't': tensor([[ -8.1925, 143.5502, 280.5694]], device='cuda:0'),\n",
       "   'time': tensor([0.0000e+00, 3.3367e-02, 6.6733e-02,  ..., 2.0254e+02, 2.0257e+02,\n",
       "           2.0260e+02], device='cuda:0'),\n",
       "   'shape': torch.Size([6073, 3, 1080, 1920])}],\n",
       " 'targets': [<torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e68b7bf0>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e678e870>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2cc62f080>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc10f576d50>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2d43a1a00>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc2cc726150>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc10f8fbc80>,\n",
       "  <torchcodec.decoders._video_decoder.VideoDecoder at 0x7fc0e69e1df0>],\n",
       " 'n_frames': 6073}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = dataset_full[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 64, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.n_frames = 10\n",
    "\n",
    "for i in s.sources:\n",
    "    i.video = i.video[:s.n_frames][:, :, :64, :64]\n",
    "    i.shape = torch.Size((s.n_frames, 3, 64, 64))\n",
    "for i in s.queries:\n",
    "    i.video = i.video[:s.n_frames][:, :, :64, :64]\n",
    "    i.shape = torch.Size((s.n_frames, 3, 64, 64))\n",
    "for i in range(len(s.targets)):\n",
    "    s.targets[i] = s.targets[i][:s.n_frames][:, :, :64, :64]\n",
    "\n",
    "s.sources[0].video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with amp.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "    out = model(s)\n",
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# configure transformer enc and dec layers\n",
    "# add optimizations checkpointing mixed precision etc\n",
    "# do first testing of model w small parameters and check how much the pc can handle of it\n",
    "# create combinations of configs for small experiments\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
